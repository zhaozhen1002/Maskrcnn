{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pretrained model to C:\\Users\\pasonatech\\Desktop\\car_detection\\tensorflow\\Mask_RCNN\\mask_rcnn_coco.h5 ...\n",
      "... done downloading pretrained model!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0922 10:32:45.087541 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0922 10:32:45.144534 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0922 10:32:45.188582 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0922 10:32:45.227576 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0922 10:32:45.238535 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0922 10:32:48.174577 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0922 10:32:49.656565 18812 deprecation.py:323] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0922 10:32:49.822567 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Desktop\\car_detection\\tensorflow\\Mask_RCNN\\mrcnn\\model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "W0922 10:32:49.907577 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Desktop\\car_detection\\tensorflow\\Mask_RCNN\\mrcnn\\utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0922 10:32:49.939574 18812 deprecation.py:506] From C:\\Users\\pasonatech\\Desktop\\car_detection\\tensorflow\\Mask_RCNN\\mrcnn\\model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    }
   ],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\pasonatech\\Desktop\\car_detection\\tensorflow\\Mask_RCNN\\logs\\shapes20190922T1033\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0922 10:33:23.179643 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "W0922 10:33:30.520613 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0922 10:33:30.521638 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 1382s 14s/step - loss: 1.8056 - rpn_class_loss: 0.0327 - rpn_bbox_loss: 0.6437 - mrcnn_class_loss: 0.3504 - mrcnn_bbox_loss: 0.4270 - mrcnn_mask_loss: 0.3517 - val_loss: 0.9588 - val_rpn_class_loss: 0.0160 - val_rpn_bbox_loss: 0.4547 - val_mrcnn_class_loss: 0.1765 - val_mrcnn_bbox_loss: 0.1689 - val_mrcnn_mask_loss: 0.1426\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 1. LR=0.0001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\pasonatech\\Desktop\\car_detection\\tensorflow\\Mask_RCNN\\logs\\shapes20190922T1033\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\pasonatech\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "100/100 [==============================] - 1619s 16s/step - loss: 0.8414 - rpn_class_loss: 0.0168 - rpn_bbox_loss: 0.4279 - mrcnn_class_loss: 0.1280 - mrcnn_bbox_loss: 0.1354 - mrcnn_mask_loss: 0.1332 - val_loss: 0.9084 - val_rpn_class_loss: 0.0165 - val_rpn_bbox_loss: 0.5164 - val_mrcnn_class_loss: 0.1135 - val_mrcnn_bbox_loss: 0.1276 - val_mrcnn_mask_loss: 0.1345\n"
     ]
    }
   ],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0922 11:33:20.887337 18812 deprecation_wrapper.py:119] From C:\\Users\\pasonatech\\Desktop\\car_detection\\tensorflow\\Mask_RCNN\\mrcnn\\model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n",
      "W0922 11:33:21.021315 18812 deprecation.py:323] From C:\\Users\\pasonatech\\Desktop\\car_detection\\tensorflow\\Mask_RCNN\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  C:\\Users\\pasonatech\\Desktop\\car_detection\\tensorflow\\Mask_RCNN\\logs\\shapes20190922T1033\\mask_rcnn_shapes_0002.h5\n",
      "Re-starting from epoch 2\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_image           shape: (128, 128, 3)         min:   12.00000  max:  239.00000  uint8\n",
      "image_meta               shape: (16,)                 min:    0.00000  max:  128.00000  int32\n",
      "gt_class_id              shape: (1,)                  min:    3.00000  max:    3.00000  int32\n",
      "gt_bbox                  shape: (1, 4)                min:   23.00000  max:  128.00000  int32\n",
      "gt_mask                  shape: (128, 128, 1)         min:    0.00000  max:    1.00000  bool\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (128, 128, 3)         min:   12.00000  max:  239.00000  uint8\n",
      "molded_images            shape: (1, 128, 128, 3)      min: -111.70000  max:  122.20000  float64\n",
      "image_metas              shape: (1, 16)               min:    0.00000  max:  128.00000  int32\n",
      "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP:  0.95\n"
     ]
    }
   ],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
